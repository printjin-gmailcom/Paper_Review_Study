# **멀티모달 논문 스터디**

## **개요**

이 레포지토리는 **2025년 7월 1일**부터 진행된 멀티모달 관련 논문 리뷰 스터디의 자료를 정리한 것입니다.

## **주요 특징**

- 멀티모달 학습의 기초 논문 리뷰
- 비전-언어 모델 등 다양한 멀티모달 아키텍처 분석

## Paper List

| Date      | Paper                                                                                              | Topic                                    | Links                                     |
| --------- | -------------------------------------------------------------------------------------------------- | ---------------------------------------- | ----------------------------------------- |
| 2025.7.1  | Attention Is All You Need                                                                          | Transformer, Self-Attention              | [paper](https://arxiv.org/abs/1706.03762) |
| 2025.7.6  | Learning Transferable Visual Models From Natural Language Supervision                              | Vision-Language Pretraining, CLIP        | [paper](https://arxiv.org/abs/2103.00020) |
| 2025.7.13 | Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation | Vision-Language Pretraining, BLIP        | [paper](https://arxiv.org/abs/2201.12086) |
| 2025.7.13 | Align before Fuse: Vision and Language Representation Learning with Momentum Distillation          | Vision-Language Pretraining              | [paper](https://arxiv.org/abs/2107.07651) |
| 2025.7.20 | GIT: A Generative Image-to-text Transformer for Vision and Language                                | Vision-Language, Image Captioning        | [paper](https://arxiv.org/abs/2205.14100) |
| 2025.7.27 | Flamingo: a Visual Language Model for Few-Shot Learning                                            | Vision-Language, Few-Shot Learning       | [paper](https://arxiv.org/abs/2204.14198) |
| 2025.8.3  | Visual Instruction Tuning                                                                          | Vision-Language, Instruction Tuning      | [paper](https://arxiv.org/pdf/2304.08485) |
| 2025.8.10 | InstructBLIP: Towards General-purpose Vision-Language Models with Instruction Tuning               | Vision-Language, Instruction Pretraining | [paper](https://arxiv.org/abs/2305.06500) |
| 2025.8.17 | Osprey: Pixel Understanding with Visual Instruction Tuning                                         | Vision-Language, Pixel-Level Instruction | [paper](https://arxiv.org/pdf/2312.10032) |
