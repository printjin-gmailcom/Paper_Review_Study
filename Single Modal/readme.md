# **싱글모달 논문 스터디**

## **개요**

이 레포지토리는 **2025년 7월 1일**부터 진행된 싱글모달 관련 논문 리뷰 스터디 자료를 정리한 것입니다.

## **주요 특징**

* NLP, Vision, Voice 등 싱글모달 학습 관련 기초 및 최신 논문 리뷰
* Word Embedding, Transformer, Seq2Seq, Contextual Representation, CNN 등 다양한 싱글모달 아키텍처 분석

## Paper List

| 날짜 | 논문 제목 | 주제 | 링크 |
| --------- | --------------------------------------------------------------------------------- | ------------------------------------ | ---------------------------------------------------------------------------------------------------------- |
| 2025.7.5  | Attention Is All You Need | Transformer, Self-Attention | [paper](https://arxiv.org/abs/1706.03762) |
| 2025.7.12 | Efficient Estimation of Word Representations in Vector Space | Word Embedding, Skip-gram | [paper](https://arxiv.org/abs/1301.3781) |
| 2025.7.19 | Glove: Global Vectors for Word Representation | Word Embedding, Co-occurrence Matrix | [paper](https://www.researchgate.net/publication/284576917_Glove_Global_Vectors_for_Word_Representation) |
| 2025.7.26 | Sequence to Sequence Learning with Neural Networks | Seq2Seq, Encoder-Decoder | [paper](https://arxiv.org/pdf/1409.3215) |
| 2025.8.2  | Deep contextualized word representations | Contextual Word Embedding, ELMo | [paper](https://arxiv.org/abs/1802.05365) |
| 2025.8.9  | BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding  | Language Representation, BERT | [paper](https://arxiv.org/pdf/1810.04805) |
| 2025.8.16 | Language Models are Few-Shot Learners | GPT-3, Few-Shot Learning | [paper](https://arxiv.org/pdf/2005.14165) |
| 2025.8.30 | Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer | T5, Text-to-Text Transfer Learning | [paper](https://arxiv.org/abs/1910.10683) |
| 2025.9.13 | ImageNet Classification with Deep Convolutional Neural Networks (AlexNet) | CNN, Image Classification | [paper](https://papers.nips.cc/paper_files/paper/2012/hash/c399862d3b9d6b76c8436e924a68c45b-Abstract.html) |
| 2025.9.20 | Very Deep Convolutional Networks for Large-Scale Image Recognition (VGG16) | CNN, Deep Learning | [paper](https://arxiv.org/abs/1409.1556) |
| 2025.9.27 | Going Deeper with Convolutions | CNN, Inception | [paper](https://arxiv.org/pdf/1409.4842) |
| 2025.10.04 | Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks | Object Detection, RPN, CNN| [paper](https://arxiv.org/pdf/1506.01497) |
| 2025.10.11 | End-to-End Object Detection with Transformers| Object Detection, Transformer, DETR | [paper](https://arxiv.org/abs/2005.12872)|
| 2025.10.18 | Deep Speech: Scaling up end-to-end speech recognition| Speech Recognition, RNN, CTC, End-to-End | [paper](https://arxiv.org/abs/1412.5567) |
| 2025.10.25 | Deep Speech 2: End-to-End Speech Recognition in English and Mandarin | Speech Recognition, RNN, BatchNorm, End-to-End | [paper](https://arxiv.org/abs/1512.02595) |
| 2025.11.08 | Is Space-Time Attention All You Need for Video Understanding? | Video Understanding, Transformer, Attention, TimeSformer | [paper](https://arxiv.org/abs/2102.05095) |
